{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 번역 전 문장 / 번역 후 문장 / 실제 번역 정답 문장\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich',\n",
       " 'mochte',\n",
       " 'ein',\n",
       " 'bier',\n",
       " 'P',\n",
       " 'S',\n",
       " 'i',\n",
       " 'want',\n",
       " 'a',\n",
       " 'beer',\n",
       " 'i',\n",
       " 'want',\n",
       " 'a',\n",
       " 'beer',\n",
       " 'E']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세가지 문장을 임베딩하기 위해서 모든 문장 내 등장하는 단어 리스트와 해당 단어들의 빈도?를 나타내는 딕셔너리 생성\n",
    "word_list = \" \".join(sentences).split() \n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich', 'P', 'ein', 'i', 'S', 'beer', 'a', 'bier', 'want', 'mochte', 'E']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set(word_list) # 중복제거\n",
    "word_list = list(set(word_list))\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 10,\n",
       " 'P': 1,\n",
       " 'S': 4,\n",
       " 'a': 6,\n",
       " 'beer': 5,\n",
       " 'bier': 7,\n",
       " 'ein': 2,\n",
       " 'i': 3,\n",
       " 'ich': 0,\n",
       " 'mochte': 9,\n",
       " 'want': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ich',\n",
       " 1: 'P',\n",
       " 2: 'ein',\n",
       " 3: 'i',\n",
       " 4: 'S',\n",
       " 5: 'beer',\n",
       " 6: 'a',\n",
       " 7: 'bier',\n",
       " 8: 'want',\n",
       " 9: 'mochte',\n",
       " 10: 'E'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "number_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class = len(word_dict) # vocab list\n",
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "hidden = torch.zeros(1, 1, n_hidden)\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 앞서 만든 단어 빈도 딕셔너리를 기반으로 문장 임베딩\n",
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # n_class : 문장 크기, hidden_size : input 은닉층 차원 \n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5) # dropout 참고 : https://pythonkim.tistory.com/42\n",
    "\n",
    "        # Linear for attention : 어느시점에 쓰이는가?\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden) # 128, 128  -> attention score구할 때 쓰임\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class) # 256, 11 (vocab list)\n",
    "        \n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        \n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)  # enc_inputs : 실제 인풋값, hidden : 지정 사이즈\n",
    "        \n",
    "        trained_attn = []  # 디코더 step별 인코더 dot을 통해 나온 attention distribution을 취합\n",
    "        hidden = enc_hidden  # hidden : encoder를 거쳐 나온 은닉\n",
    "        n_step = len(dec_inputs) # dec_inputs : 'S i want a beer'\n",
    "        model = torch.empty([n_step, 1, n_class])  # model?\n",
    "        \n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)  # 디코더 전이\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]  # 디코더 step마다 모든 인코더의 dot product를 수행하여 attention score 구함\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "    \n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)  \n",
    "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):  # 인코더 크기만큼 반복\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])  # 디코더와 각 인코더를 dot product 수행\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)  # softmax로 attention distribution을 만듬(스코어간 편차를 키움)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghdls\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "C:\\Users\\ghdls\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000484\n",
      "Epoch: 0800 cost = 0.000156\n",
      "Epoch: 1200 cost = 0.000077\n",
      "Epoch: 1600 cost = 0.000046\n",
      "Epoch: 2000 cost = 0.000030\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAE2CAYAAADoC7CBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsZSkBsZSkhoYS0lq8P/guYz9ECNOYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209a4add128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n_step = 5 # number of cells(= number of Step)\n",
    "    n_hidden = 128 # number of hidden units in one cell\n",
    "\n",
    "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "    n_class = len(word_dict)  # vocab list\n",
    "\n",
    "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "    model = Attention()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "        loss = criterion(output, target_batch.squeeze(0))\n",
    "        if (epoch + 1) % 400 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test\n",
    "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "    test_batch = torch.FloatTensor(test_batch)\n",
    "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "    predict = predict.data.max(1, keepdim=True)[1]\n",
    "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "    # Show Attention\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(trained_attn, cmap='viridis')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
