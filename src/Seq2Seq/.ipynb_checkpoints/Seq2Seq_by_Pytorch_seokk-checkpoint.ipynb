{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 개념 짚고가기\n",
    "\n",
    "- Seq2Seq(Encoder-Decoder LSTM)모델은 RNN을 이용해 input을 feature vector로 인코딩함\n",
    "- 이렇게 인코딩된 vector를 여기선 'context vector'라 함\n",
    "- 'context vector' : input문장의 추상적인/압축된 representation\n",
    "- 이 context vector는 두번째 RNN을 통해 디코딩되어 번역된 문장을 생성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manPP\n",
      "women\n",
      "black\n",
      "white\n",
      "kingP\n",
      "queen\n",
      "girlP\n",
      "boyPP\n",
      "upPPP\n",
      "downP\n",
      "highP\n",
      "lowPP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_batch, output_batch, target_batch = [], [], []\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_step = 5\n",
    "    \n",
    "for seq in seq_data:\n",
    "    # print(seq) # Output : one row\n",
    "    for i in range(2):  # Check each one by one\n",
    "       # print(seq)\n",
    "       # print(n_step - len(seq[i]))\n",
    "        seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) # add 'P'\n",
    "        print(seq[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 1,\n",
       " 'P': 2,\n",
       " 'S': 0,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "num_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 3, 16, 2, 2]\n",
      "[4, 14, 3, 5, 13]\n",
      "[13, 11, 16, 9, 2]\n",
      "[9, 11, 20, 14, 2]\n",
      "[23, 18, 2, 2, 2]\n",
      "[10, 11, 9, 10, 2]\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch, target_batch = [], [], []\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_step = 5\n",
    "    \n",
    "for seq in seq_data:\n",
    "    # print(seq)  # Output : one row\n",
    "    for i in range(2):  # Check each one by one\n",
    "       # print(seq)\n",
    "       # print(n_step - len(seq[i]))\n",
    "        seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) # add 'P'\n",
    "        #print(seq[i])\n",
    "    input = [num_dic[n] for n in seq[0]] # 인코더 셀의 입력값. 입력단어의 글자들을 한글자씩 떼어 배열로 임베딩한다.\n",
    "    print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 17, 15, 7, 16, 1]\n",
      "[25, 10, 11, 22, 7, 1]\n",
      "[19, 23, 7, 7, 16, 1]\n",
      "[4, 17, 27, 2, 2, 1]\n",
      "[6, 17, 25, 16, 2, 1]\n",
      "[14, 17, 25, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch, target_batch = [], [], []\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "n_step = 5\n",
    "    \n",
    "for seq in seq_data:\n",
    "    # print(seq)  # Output : one row\n",
    "    for i in range(2):  # Check each one by one\n",
    "       # print(seq)\n",
    "       # print(n_step - len(seq[i]))\n",
    "        seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) # add 'P'\n",
    "        #print(seq[i])\n",
    "    input = [num_dic[n] for n in seq[0]] # encoder\n",
    "    output = [num_dic[n] for n in ('S' + seq[1])] # decoer\n",
    "    target = [num_dic[n] for n in (seq[1] + 'E')] # training data\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Seq2Seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8ad2fed7f5d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Seq2Seq' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# S: 디코딩 입력의 시작을 나타내는 심볼\n",
    "# E: 디코딩 출력을 끝을 나타내는 심볼\n",
    "# P: 현재 배치 데이터의 time step 크기보다 작은 경우 빈 시퀀스를 채우는 심볼\n",
    "#    예) 현재 배치 데이터의 최대 크기가 4 인 경우\n",
    "#       word -> ['w', 'o', 'r', 'd']\n",
    "#       to   -> ['t', 'o', 'P', 'P']\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    n_step = 5\n",
    "    n_hidden = 128\n",
    "\n",
    "    char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "    num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "    # 학습데이터\n",
    "    seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "    n_class = len(num_dic)\n",
    "    batch_size = len(seq_data)\n",
    "\n",
    "    model = Seq2Seq()\n",
    "    \n",
    "\n",
    "def make_batch(): # batch?\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) # 학습데이터를 로드하여 char단위로 확인. n_step보다 짧을경우 P로 채움\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]] # 인코더 셀의 입력값. 입력단어의 글자들을 한글자씩 떼어 배열로 만든다.\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])] # 디코더 셀의 입력값. 시작을 나타내는 S 심볼을 맨 앞에 붙여준다.\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')] # 학습을 위해 비교할 디코더 셀의 출력값. 끝나는 것을 알려주기 위해 마지막에 E를 붙인다.\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input]) # one-hot?  # return 결과 봐야할듯\n",
    "        output_batch.append(np.eye(n_class)[output])\n",
    "        target_batch.append(target) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose(0, 1) # enc_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "        dec_input = dec_input.transpose(0, 1) # dec_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_states : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len+1(=6), batch_size, num_directions(=1) * n_hidden(=128)]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        model = self.fc(outputs) # model : [max_len+1(=6), batch_size, n_class]\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
