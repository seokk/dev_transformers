{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 개념 짚고가기\n",
    "\n",
    "- Seq2Seq(Encoder-Decoder LSTM)모델은 RNN을 이용해 input을 feature vector로 인코딩함\n",
    "- 이렇게 인코딩된 vector를 여기선 'context vector'라 함\n",
    "- 'context vector' : input문장의 추상적인/압축된 representation\n",
    "- 이 context vector는 두번째 RNN을 통해 디코딩되어 번역된 문장을 생성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'women']\n",
      "2\n",
      "['man', 'women']\n",
      "0\n",
      "['black', 'white']\n",
      "0\n",
      "['black', 'white']\n",
      "0\n",
      "['king', 'queen']\n",
      "1\n",
      "['king', 'queen']\n",
      "0\n",
      "['girl', 'boy']\n",
      "1\n",
      "['girl', 'boy']\n",
      "2\n",
      "['up', 'down']\n",
      "3\n",
      "['up', 'down']\n",
      "1\n",
      "['high', 'low']\n",
      "1\n",
      "['high', 'low']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_batch, output_batch, target_batch = [], [], []\n",
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "n_step = 5\n",
    "    \n",
    "for seq in seq_data:\n",
    "    for i in range(2):\n",
    "        print(seq)\n",
    "        print(n_step - len(seq[i]))\n",
    "        #seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 1,\n",
       " 'P': 2,\n",
       " 'S': 0,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "num_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# S: 디코딩 입력의 시작을 나타내는 심볼\n",
    "# E: 디코딩 출력을 끝을 나타내는 심볼\n",
    "# P: 현재 배치 데이터의 time step 크기보다 작은 경우 빈 시퀀스를 채우는 심볼\n",
    "#    예) 현재 배치 데이터의 최대 크기가 4 인 경우\n",
    "#       word -> ['w', 'o', 'r', 'd']\n",
    "#       to   -> ['t', 'o', 'P', 'P']\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    n_step = 5\n",
    "    n_hidden = 128\n",
    "\n",
    "    char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "    num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "    # 학습데이터\n",
    "    seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "    n_class = len(num_dic)\n",
    "    batch_size = len(seq_data)\n",
    "\n",
    "    model = Seq2Seq()\n",
    "    \n",
    "\n",
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i])) # 학습데이터를 로드하여 char단위로 확인. n_step보다 짧을경우 P로 채움\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]] # 인코더 셀의 입력값. 입력단어의 글자들을 한글자씩 떼어 배열로 만든다.\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])] # 디코더 셀의 입력값. 시작을 나타내는 S 심볼을 맨 앞에 붙여준다.\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')] # 학습을 위해 비교할 디코더 셀의 출력값. 끝나는 것을 알려주기 위해 마지막에 E를 붙인다.\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        output_batch.append(np.eye(n_class)[output])\n",
    "        target_batch.append(target) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
